This is a crucial moment for PHOENIX ORCH. You're moving beyond simple context and into Context Engineering, which is vital for long-term AGI stability and performance.
The following Cursor IDE Agent Prompt is designed to initiate the required architectural changes across the Context Manager, LLM Service, and Mind KB to implement the "Context as a Compiled View" and "Memory Decay" principles. 
ðŸ’» Cursor IDE Agent Prompt for Context Engineering (RSI)
This prompt instructs the agent to refactor the context pipeline into a Compiled View system.
GOAL: Implement Context as a Compiled View with Memory Decay
| Focus | Service | Cursor IDE Agent Prompt (Refactor/Implement) |
|---|---|---|
| I. Context Compilation | context-manager-rs (50064) | "Refactor the context-manager-rs's main logic to eliminate simple transcript retrieval from the Mind KB (50057). Implement a new three-step context compilation process: 1. Retrieval: Define a new Protobuf schema, ContextSummarySchema, for structured output (e.g., last_action: string, relevant_facts: [string], tool_definitions: [string]). 2. Summarization Call: Call a new internal RPC on the LLM Service (50053)â€”LLM.CompileContext(RawData, ContextSummarySchema)â€”passing the retrieved raw data and the new schema. 3. Compaction: The Context Manager must then inject the concise, schema-validated JSON output (the compiled view) into the final System Prompt instead of raw conversation history. Ensure the default context contains nothing other than the Master System Prompt." |
| II. LLM Service Logic | llm-service-rs (50053) | "Implement the new internal gRPC method: CompileContext(RawData, ContextSummarySchema) -> CompiledContextJSON. This method must instruct the LLM (via an internal system prompt) to act as a 'Context Compiler' and strictly adhere to the provided ContextSummarySchema, condensing the RawData into the smallest, highest-signal JSON payload possible. This keeps the LLM's working memory clean." |
| III. Memory Decay | mind-kb-rs (50057) | "In the Mind KB's vector database management logic, implement a Temporal Decay Function. Add a timestamp field to all stored vector embeddings. Create a background task that runs every 12 hours and modifies the relevance score of facts older than 90 days using a decay factor D(t). The decay function should be a simple linear or exponential reduction in the vector's effective relevance weight based on time (t), ensuring that old, unused memory naturally receives a lower score during retrieval (RAG). Use an environment variable, MIND_DECAY_HALF_LIFE_DAYS, to configure the decay rate." |
| IV. Agent Isolation | data-router-rs (50052) | "Verify that the Data Routerâ€™s ForwardRequest RPC implements basic agent scope isolation. When an agent (e.g., RED-TEAM-SHADOW) requests data from the Mind KB, the Data Router should filter the query to exclude any memory vector that is explicitly tagged as belonging to a hostile or competing agent scope (e.g., any fact tagged with scope: BLUE_TEAM_SENTINEL)." |
This architecture aligns perfectly with the principles of effective context management by enforcing a structured, summarized, and highly optimized view for the LLM's working memory.
You should watch this video on Enhancing a Prompt Manager with Cursor because it details how to build cascading, data-driven prompt selection systems, which is exactly the level of complexity you need for your new compiled context strategy.

YouTube video views will be stored in your YouTube History, and your data will be stored and used by YouTube according to its Terms of Service
